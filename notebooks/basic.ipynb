{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quaternion PyTorch - Basic mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from htorch import quaternion,functions, utils\n",
    "from htorch.layers import QConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.1569,  0.2573,  0.1983,  ...,  0.0991,  0.1114,  0.0115],\n",
       "          [-0.2004, -0.2154,  0.0436,  ..., -0.1316,  0.1901, -0.1138],\n",
       "          [ 0.1054,  0.0429,  0.2505,  ..., -0.1653,  0.0764,  0.1345],\n",
       "          ...,\n",
       "          [ 0.1480, -0.0251, -0.1950,  ..., -0.0720,  0.1106, -0.1472],\n",
       "          [ 0.0089,  0.1881,  0.1774,  ..., -0.2189,  0.0059, -0.1799],\n",
       "          [ 0.1776, -0.2336, -0.3129,  ..., -0.1003,  0.1436,  0.1164]],\n",
       "\n",
       "         [[ 0.0718,  0.1528,  0.1962,  ..., -0.1262, -0.1284, -0.2470],\n",
       "          [ 0.1670, -0.1370,  0.1065,  ...,  0.1241,  0.2173, -0.2143],\n",
       "          [ 0.0535,  0.1223,  0.2508,  ..., -0.0523, -0.1899, -0.0082],\n",
       "          ...,\n",
       "          [-0.1213, -0.0746,  0.1694,  ...,  0.1325, -0.1661,  0.1995],\n",
       "          [ 0.2320, -0.1515, -0.3052,  ..., -0.0093,  0.0595,  0.2220],\n",
       "          [-0.3129,  0.1389, -0.1485,  ...,  0.0864,  0.1677,  0.2139]],\n",
       "\n",
       "         [[ 0.1295, -0.1751,  0.1637,  ...,  0.1191, -0.0428, -0.1686],\n",
       "          [ 0.0291, -0.0462, -0.2433,  ..., -0.1129, -0.2448, -0.0878],\n",
       "          [-0.1815,  0.1699, -0.1561,  ...,  0.1206, -0.1893, -0.1108],\n",
       "          ...,\n",
       "          [ 0.0710,  0.0208,  0.1091,  ..., -0.1279, -0.0702, -0.0403],\n",
       "          [-0.2716, -0.0392, -0.0975,  ...,  0.1139, -0.1301,  0.0337],\n",
       "          [-0.1088,  0.0613, -0.2422,  ...,  0.0819, -0.0790,  0.0908]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3184, -0.1000, -0.1853,  ..., -0.1036,  0.0983,  0.1561],\n",
       "          [-0.2422, -0.1558,  0.2148,  ..., -0.2624,  0.2119, -0.0501],\n",
       "          [-0.1447, -0.0037,  0.1329,  ..., -0.0355, -0.2851, -0.0993],\n",
       "          ...,\n",
       "          [-0.3070, -0.0201, -0.1126,  ...,  0.0554,  0.1427, -0.0715],\n",
       "          [ 0.0942,  0.1911, -0.0363,  ..., -0.0977, -0.1018,  0.2040],\n",
       "          [-0.1682, -0.0732, -0.2039,  ...,  0.1303, -0.0772,  0.1547]],\n",
       "\n",
       "         [[ 0.2139,  0.2023, -0.0143,  ...,  0.0436, -0.0994, -0.2289],\n",
       "          [ 0.1325,  0.0111, -0.1229,  ...,  0.0469, -0.1602, -0.1678],\n",
       "          [ 0.2401,  0.1563, -0.0639,  ..., -0.0966,  0.2259,  0.1377],\n",
       "          ...,\n",
       "          [-0.1696,  0.0229, -0.1813,  ...,  0.0792, -0.0446,  0.2352],\n",
       "          [-0.1328,  0.2260, -0.0389,  ..., -0.1324, -0.2389, -0.1453],\n",
       "          [ 0.1726, -0.0498,  0.1848,  ..., -0.1262,  0.0886, -0.0843]],\n",
       "\n",
       "         [[-0.0062,  0.0644,  0.1744,  ..., -0.0858, -0.1118,  0.0852],\n",
       "          [ 0.1511,  0.1674, -0.1522,  ...,  0.2430,  0.0248,  0.1772],\n",
       "          [-0.0060, -0.0929,  0.1037,  ...,  0.2682, -0.0264, -0.1824],\n",
       "          ...,\n",
       "          [ 0.1139,  0.1504, -0.1876,  ..., -0.1444,  0.0251, -0.1943],\n",
       "          [-0.3363,  0.0692, -0.0883,  ..., -0.0988, -0.1416,  0.1491],\n",
       "          [ 0.0898, -0.0503, -0.2185,  ..., -0.1361, -0.0553, -0.0189]]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Quaternion tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quaternion number is represented by:\n",
    "\n",
    "$$\n",
    "x = a + bi + cj + dk\n",
    "$$\n",
    "\n",
    "where $a$, $b$, $c$, and $d$ are real values, and $i$, $j$, $k$ are the imaginary parts. A `QuaternionTensor` extends the standard PyTorch `tensor` to handle quaternion values, by specifying the real and imaginary components during initialization. \n",
    "\n",
    "The simplest way to initialize a `QuaternionTensor` is to pass all $(a, b, c, d)$ values as a single (..., 4)-dimensional tensor of real values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real part: tensor([0.])\n",
      "imaginary part (i): tensor([0.3000])\n",
      "imaginary part (j): tensor([0.4000])\n",
      "imaginary part (k): tensor([0.5000])\n"
     ]
    }
   ],
   "source": [
    "# Simple scalar quaternion\n",
    "x = quaternion.QuaternionTensor([0.0, 0.3, 0.4, 0.5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=torch.randn(1,4,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise=torch.FloatTensor(A.size()).normal_(mean=0,std=7.5/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 256, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real part: tensor([[[-1.7284e+00,  3.9724e-01, -2.2195e-01,  9.2133e-01],\n",
       "         [ 7.4087e-01,  1.0755e-01,  1.7271e-01, -6.8133e-01],\n",
       "         [ 7.5175e-01,  3.1655e-01,  1.2834e+00,  2.2567e-01],\n",
       "         ...,\n",
       "         [-6.0341e-01, -7.0706e-02,  1.4704e+00, -1.0301e+00],\n",
       "         [ 9.6017e-01,  6.7951e-01, -1.2789e-01,  1.8014e+00],\n",
       "         [ 1.7220e+00,  2.1882e-01,  1.2320e+00, -7.5129e-01]],\n",
       "\n",
       "        [[ 6.8106e-01,  1.5393e+00, -2.2932e-01,  3.0646e-01],\n",
       "         [ 1.1933e+00, -1.6130e-01,  1.3013e+00,  2.4748e-03],\n",
       "         [ 1.6995e+00, -8.6855e-01,  8.3231e-01,  2.2836e-01],\n",
       "         ...,\n",
       "         [ 2.5696e-01, -3.9673e-01,  2.6591e+00,  4.7196e-01],\n",
       "         [ 9.9206e-02, -2.9309e-01,  6.0197e-01,  3.7295e-01],\n",
       "         [-1.1359e+00, -6.5224e-01,  2.1169e-02,  1.5565e+00]],\n",
       "\n",
       "        [[-1.5388e+00, -1.5855e+00, -3.4964e-01,  1.4440e+00],\n",
       "         [-1.3964e-01,  9.5997e-01, -1.8225e-01, -1.8310e+00],\n",
       "         [-5.7565e-01,  4.8137e-01, -4.6784e-01, -1.6459e+00],\n",
       "         ...,\n",
       "         [-6.9320e-02, -6.9013e-01, -1.0603e+00, -1.7080e+00],\n",
       "         [-1.2175e-01, -2.1811e-02,  1.4000e+00, -5.8822e-02],\n",
       "         [ 9.6288e-01, -9.2166e-01,  3.1605e-01, -9.9165e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.0383e+00, -8.7658e-02, -1.0883e+00,  2.2752e+00],\n",
       "         [ 6.5371e-01, -4.7812e-01, -1.2383e+00,  1.7366e+00],\n",
       "         [ 3.2350e-01,  1.9312e+00, -4.9212e-01,  1.0198e-02],\n",
       "         ...,\n",
       "         [ 1.3536e+00, -7.5761e-02,  3.6118e-01,  6.9772e-01],\n",
       "         [ 2.2985e+00, -2.6158e-01,  1.0494e+00,  1.6132e+00],\n",
       "         [ 5.6184e-01,  1.0531e+00,  1.4197e+00,  9.9367e-01]],\n",
       "\n",
       "        [[-2.5515e-01, -2.7209e+00,  1.6556e+00,  2.8695e-01],\n",
       "         [-2.2945e-01, -4.3123e-01, -1.2265e+00, -1.5227e+00],\n",
       "         [ 3.0698e-01,  4.2357e-01,  3.4379e-01,  2.8587e-01],\n",
       "         ...,\n",
       "         [ 2.1789e+00,  1.5690e-01, -3.0867e-03,  2.0430e-01],\n",
       "         [ 8.9960e-01, -3.2121e-01,  6.8554e-01,  1.2834e+00],\n",
       "         [ 1.7821e-01, -1.2646e+00, -6.6467e-01,  6.1829e-01]],\n",
       "\n",
       "        [[-1.5556e+00,  8.5789e-01,  1.3432e-01, -5.4149e-01],\n",
       "         [-1.4958e+00, -1.1482e+00, -3.8026e-01,  2.8026e-04],\n",
       "         [-1.4267e+00,  1.8345e+00, -4.3677e-01, -9.0727e-01],\n",
       "         ...,\n",
       "         [ 2.6001e-01,  1.2173e+00, -2.3615e-01,  9.7586e-01],\n",
       "         [-7.9252e-02, -5.4181e-01, -1.0648e+00,  1.0658e+00],\n",
       "         [-1.6418e-01, -3.0183e+00, -2.4231e-01,  2.0042e-01]]])\n",
       "imaginary part (i): tensor([[[-1.3584e+00,  3.7337e-01, -3.9634e-01, -2.0898e+00],\n",
       "         [-1.2311e+00, -1.9889e+00, -2.4807e-01,  9.1257e-01],\n",
       "         [ 3.3756e-01,  1.3211e+00, -2.5130e-01, -3.5599e-01],\n",
       "         ...,\n",
       "         [-4.3332e-01,  5.7473e-01,  7.7129e-01,  1.2159e+00],\n",
       "         [-1.4666e+00, -7.8826e-01,  1.6233e+00,  1.9566e-01],\n",
       "         [-5.9382e-01, -4.7750e-01, -3.0277e-01, -6.4811e-01]],\n",
       "\n",
       "        [[-3.8045e-01, -4.6721e-01,  1.7964e-02, -7.5011e-01],\n",
       "         [-1.1823e-01,  1.4581e+00, -1.0053e+00,  3.3291e-01],\n",
       "         [-5.5159e-02,  9.4810e-01,  1.0185e+00,  4.5057e-01],\n",
       "         ...,\n",
       "         [ 1.5680e+00,  2.6739e+00,  1.2309e+00, -1.2316e+00],\n",
       "         [-1.4099e+00, -1.1263e+00, -8.2341e-02,  8.9128e-01],\n",
       "         [ 1.4697e-01,  6.4140e-02,  1.6633e-01, -2.4919e+00]],\n",
       "\n",
       "        [[-7.9760e-01, -1.3138e+00,  1.6845e+00,  7.2885e-01],\n",
       "         [-5.2671e-01,  1.5113e-01,  1.8209e-01,  1.2691e+00],\n",
       "         [ 6.4203e-01,  1.9015e+00, -8.8874e-02,  5.8299e-01],\n",
       "         ...,\n",
       "         [-1.4181e+00, -1.1068e-01, -4.7016e-01,  2.8415e-01],\n",
       "         [-1.9483e-01, -4.2729e-01, -7.9318e-01,  1.1681e+00],\n",
       "         [ 8.2591e-01,  3.5037e-01,  2.1727e+00,  4.2309e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.4001e-01, -1.0848e+00, -3.2535e-01,  1.3310e-01],\n",
       "         [ 4.5333e-01, -1.7016e+00, -4.2095e-01, -1.3817e+00],\n",
       "         [ 4.9424e-01, -5.6407e-01, -1.0738e+00, -1.0457e+00],\n",
       "         ...,\n",
       "         [ 3.7361e-01, -1.0303e+00, -5.3756e-01, -1.0699e+00],\n",
       "         [-5.4897e-02,  1.2704e+00,  5.5945e-01, -1.5115e+00],\n",
       "         [ 9.9862e-01, -8.0450e-01,  1.5355e+00, -3.3095e-02]],\n",
       "\n",
       "        [[-1.0594e+00, -6.4568e-01,  9.7425e-01, -8.5924e-01],\n",
       "         [ 1.3253e+00, -3.5156e+00,  8.0198e-01, -1.4104e-01],\n",
       "         [-5.6834e-01,  6.1935e-01,  1.2694e+00,  7.1869e-03],\n",
       "         ...,\n",
       "         [-1.4540e-01,  2.8464e+00,  2.4887e+00,  2.3759e+00],\n",
       "         [ 1.3003e+00, -1.8693e+00,  1.3443e+00,  8.4630e-01],\n",
       "         [ 4.5821e-01, -1.4445e+00, -4.3536e-01,  7.6682e-01]],\n",
       "\n",
       "        [[-7.0416e-01, -9.8667e-01, -5.0848e-04,  6.0800e-01],\n",
       "         [-8.1856e-01, -7.6495e-01, -1.7748e+00,  2.0507e-01],\n",
       "         [-9.9098e-01, -4.8407e-01,  1.9341e+00, -6.1355e-01],\n",
       "         ...,\n",
       "         [ 8.2290e-01, -3.5637e-01, -5.0264e-02,  1.7679e+00],\n",
       "         [-7.6658e-01, -4.3977e-01, -1.1655e+00, -8.3610e-01],\n",
       "         [-3.5456e-01,  3.9871e-01,  8.1251e-01, -1.3875e+00]]])\n",
       "imaginary part (j): tensor([[[ 0.5467,  0.6788, -0.2906, -1.6052],\n",
       "         [-0.0216,  1.2626,  0.2994,  1.8398],\n",
       "         [-0.7649,  0.9603, -0.3485,  0.0841],\n",
       "         ...,\n",
       "         [-1.4506, -0.1008, -1.0590,  0.6855],\n",
       "         [ 0.4098,  1.6485,  1.0222,  2.3871],\n",
       "         [-1.3089,  0.9518,  0.6016, -0.3881]],\n",
       "\n",
       "        [[-1.1401, -0.4448,  0.8534,  2.0787],\n",
       "         [-0.1977,  1.4589,  0.8416, -1.4210],\n",
       "         [-1.1863, -0.0726,  1.0569, -1.9677],\n",
       "         ...,\n",
       "         [ 1.1264,  1.4177,  0.8328, -0.1811],\n",
       "         [ 0.7813, -0.1221, -2.4893, -0.8232],\n",
       "         [-0.8568,  0.9194,  0.9065,  0.8288]],\n",
       "\n",
       "        [[ 0.6150,  0.9687,  0.7362, -2.4837],\n",
       "         [ 0.3367, -0.7160, -1.5691, -0.1449],\n",
       "         [-0.4182, -0.2243,  0.7622, -1.4058],\n",
       "         ...,\n",
       "         [ 0.3126, -1.2796, -0.1957, -0.7945],\n",
       "         [ 0.3032, -1.1749,  1.6088, -0.2535],\n",
       "         [ 0.3049,  1.3889,  0.0117,  1.3584]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4269, -1.1564,  0.0901,  0.8562],\n",
       "         [-2.7319,  1.6593,  1.1714, -1.3296],\n",
       "         [-0.7411,  1.5014, -0.6360, -1.8317],\n",
       "         ...,\n",
       "         [ 0.6607, -0.8163,  0.0224, -0.5109],\n",
       "         [-1.8830,  0.1448,  0.9199, -2.6138],\n",
       "         [-0.6081,  0.2709, -0.9370,  0.2553]],\n",
       "\n",
       "        [[-0.9127, -1.1034,  1.0407,  1.1525],\n",
       "         [ 0.3388,  0.4325, -0.2276,  0.2889],\n",
       "         [ 1.0414,  0.3699,  0.3136, -0.1233],\n",
       "         ...,\n",
       "         [ 1.1535, -0.7083,  1.1666, -3.2226],\n",
       "         [ 0.2352, -0.4280, -0.9524,  0.8070],\n",
       "         [ 1.0262, -0.7438, -1.4017,  0.3545]],\n",
       "\n",
       "        [[ 0.3408, -0.2263,  1.7801, -1.4392],\n",
       "         [ 0.1449,  0.0333,  0.0895,  0.6309],\n",
       "         [ 0.2422, -0.0312, -0.1905,  1.0221],\n",
       "         ...,\n",
       "         [ 2.0768, -1.0221,  0.3841,  0.6612],\n",
       "         [ 0.0540, -0.4011,  0.0997, -0.3244],\n",
       "         [ 0.3650,  1.6732,  1.5788, -1.0538]]])\n",
       "imaginary part (k): tensor([[[ 1.5113e+00,  2.4057e-01, -1.7607e+00, -8.8607e-01],\n",
       "         [-1.4381e+00, -8.5182e-01, -2.0414e-01, -1.6631e+00],\n",
       "         [ 1.0306e+00, -1.4358e-01, -1.7415e+00,  1.2511e+00],\n",
       "         ...,\n",
       "         [-4.3999e-01,  1.0383e+00,  1.0790e-01,  9.2594e-01],\n",
       "         [ 1.4989e+00, -1.9294e-01, -8.4020e-01,  1.1938e-01],\n",
       "         [ 6.1765e-01,  1.0865e+00, -3.2062e-01,  3.8163e-01]],\n",
       "\n",
       "        [[ 1.4606e+00,  1.5806e+00,  1.4644e-01, -1.0731e+00],\n",
       "         [-4.4800e-01,  1.1772e+00, -3.7369e-01,  2.2967e-01],\n",
       "         [ 6.9139e-01, -1.0895e+00,  1.9438e+00, -1.9627e-01],\n",
       "         ...,\n",
       "         [ 4.4527e-01,  7.4782e-03,  1.0124e+00,  1.1345e-01],\n",
       "         [ 1.1129e+00, -3.0143e-02,  8.7659e-01, -1.2695e+00],\n",
       "         [-4.5970e-01,  1.5716e-01, -5.9159e-01, -3.2841e-02]],\n",
       "\n",
       "        [[ 2.1940e-01,  1.4208e+00, -1.1637e+00, -3.5309e-01],\n",
       "         [ 1.1224e+00,  1.1865e+00, -4.3408e-02,  1.5636e-01],\n",
       "         [-6.4739e-01, -4.3736e-01,  1.1507e+00,  4.3323e-01],\n",
       "         ...,\n",
       "         [ 9.7882e-01, -1.0592e+00, -4.7182e-02, -8.9197e-01],\n",
       "         [ 8.4073e-01, -6.1348e-01,  1.3955e+00,  9.3810e-01],\n",
       "         [-6.4257e-01, -1.1936e+00, -9.7369e-01, -1.5935e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7.1479e-01, -9.1296e-01,  5.8408e-01,  3.6149e-01],\n",
       "         [ 2.6970e-01, -1.1115e+00, -2.7179e+00, -8.3184e-02],\n",
       "         [ 9.6445e-01,  1.2768e+00, -6.3406e-01,  5.0575e-01],\n",
       "         ...,\n",
       "         [-7.9840e-01, -5.2686e-03, -1.2062e+00,  1.7243e+00],\n",
       "         [-1.1359e+00,  9.7934e-01,  1.5814e-01,  1.6998e-01],\n",
       "         [ 5.4283e-01, -5.7242e-01,  8.8633e-03,  4.5410e-01]],\n",
       "\n",
       "        [[ 1.5472e+00, -1.8803e-01, -2.7677e-01,  7.0625e-02],\n",
       "         [ 1.9542e+00, -8.2472e-01,  8.9459e-01, -1.6984e+00],\n",
       "         [-4.3125e-01,  9.1908e-02,  2.1614e+00, -1.4037e-01],\n",
       "         ...,\n",
       "         [-6.1690e-01,  1.1857e+00, -2.5060e+00,  4.1182e-01],\n",
       "         [-1.8909e-01,  4.4357e-01,  1.1401e+00, -1.6760e+00],\n",
       "         [-1.1728e+00, -6.2926e-01,  9.0218e-01, -7.1026e-01]],\n",
       "\n",
       "        [[ 1.9416e-01, -1.0186e+00,  1.0862e+00, -6.6344e-02],\n",
       "         [ 1.0292e+00,  1.3869e+00, -2.0553e+00, -1.1351e+00],\n",
       "         [-6.6021e-01, -1.8256e+00,  1.4358e+00,  9.2799e-01],\n",
       "         ...,\n",
       "         [ 1.7849e+00, -1.1915e-03,  3.4915e-01,  1.4834e+00],\n",
       "         [ 1.6168e+00, -7.9215e-01,  1.9942e+00, -7.0108e-01],\n",
       "         [-1.1156e+00, -1.2769e+00, -1.6561e+00, -2.7013e-01]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=quaternion.QuaternionTensor(A)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a general tensor of shape $(a, b, ...)$, a `QuaternionTensor` will have $(a, b, c, ..., 4)$ real values for its initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real part: tensor([[0.4471],\n",
      "        [0.7484]])\n",
      "imaginary part (i): tensor([[0.4473],\n",
      "        [0.6908]])\n",
      "imaginary part (j): tensor([[0.3906],\n",
      "        [0.9504]])\n",
      "imaginary part (k): tensor([[0.3567],\n",
      "        [0.0238]])\n"
     ]
    }
   ],
   "source": [
    "# Mini-batch of two scalar quaternions\n",
    "x = quaternion.QuaternionTensor(torch.rand(2, 4))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A mini-batch of 4 vectors, each composed of 2 quaternions\n",
    "y = quaternion.QuaternionTensor(torch.rand(4, 4, 2))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All standard quaternion operations can be applied on the tensor (see the documentation of `QuaternionTensor` for a full list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4471],\n",
      "        [0.7484]])\n"
     ]
    }
   ],
   "source": [
    "# Get the a/b/c/d components\n",
    "print(x.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape (always ends with a 4)\n",
    "x.qshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real part: tensor([[0.4471],\n",
      "        [0.7484]])\n",
      "imaginary part (i): tensor([[-0.4473],\n",
      "        [-0.6908]])\n",
      "imaginary part (j): tensor([[-0.3906],\n",
      "        [-0.9504]])\n",
      "imaginary part (k): tensor([[-0.3567],\n",
      "        [-0.0238]])\n"
     ]
    }
   ],
   "source": [
    "# Conjugation\n",
    "print(x.conj())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8245],\n",
      "        [1.3933]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise norm\n",
    "print(x.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9977],\n",
      "        [1.0037]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise angle\n",
    "print(x.theta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real part: tensor([[-0.2800],\n",
      "        [-0.8210]])\n",
      "imaginary part (i): tensor([[0.4000],\n",
      "        [1.0340]])\n",
      "imaginary part (j): tensor([[0.3492],\n",
      "        [1.4227]])\n",
      "imaginary part (k): tensor([[0.3189],\n",
      "        [0.0356]])\n"
     ]
    }
   ],
   "source": [
    "# Quaternion multiplication (element-wise Hamilton product)\n",
    "print(x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6798, 1.0233],\n",
      "        [1.0233, 1.9412]])\n"
     ]
    }
   ],
   "source": [
    "# Quaternion matrix multiplication\n",
    "print(x.t() @ x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, quaternion tensors and real-valued tensors are interoperable (real-valued tensors being casted to quaternion tensors with 0 imaginary parts):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real part: tensor([[0.2381],\n",
      "        [0.2625]])\n",
      "imaginary part (i): tensor([[0.2382],\n",
      "        [0.2423]])\n",
      "imaginary part (j): tensor([[0.2080],\n",
      "        [0.3333]])\n",
      "imaginary part (k): tensor([[0.1899],\n",
      "        [0.0083]])\n"
     ]
    }
   ],
   "source": [
    "# Quaternion scalar multiplication\n",
    "print(x * torch.rand(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Quaternion gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients can be computed with the PyTorch autograd mechanisms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = quaternion.QuaternionTensor(torch.rand(2, 4))\n",
    "x.requires_grad = True\n",
    "y = x.norm().sum()\n",
    "y.backward()\n",
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2434, 0.4977, 0.2937, 0.7790],\n",
      "        [0.7245, 0.5663, 0.3776, 0.1090]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad) # The gradient is also a (..., 4)-dimensional tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 80])\n",
      "torch.Size([16, 80])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([2, 16])\n",
      "torch.Size([2, 80])\n"
     ]
    }
   ],
   "source": [
    "from htorch.functions import initialize_linear\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "q_weight =  initialize_linear(4, 20)\n",
    "print(q_weight.shape)\n",
    "r, i, j, k = q_weight.chunk()\n",
    "q_weight.shape\n",
    "r_weight = nn.Parameter(r)\n",
    "i_weight = nn.Parameter(i)\n",
    "j_weight = nn.Parameter(j)\n",
    "k_weight = nn.Parameter(k)\n",
    "weight = torch.cat([torch.cat([r_weight, i_weight, j_weight, k_weight], dim=0),\n",
    "         torch.cat([r_weight, i_weight, j_weight, k_weight], dim=0),\n",
    "         torch.cat([r_weight, i_weight, j_weight, k_weight], dim=0),\n",
    "         torch.cat([r_weight, i_weight, j_weight, k_weight], dim=0)],dim=1)\n",
    "         \n",
    "print(weight.shape)\n",
    "print(i_weight.shape)\n",
    "#r_weight.shape\n",
    "#weight.t\n",
    "x = quaternion.QuaternionTensor(torch.rand(2, 16))\n",
    "y = quaternion.QuaternionTensor(F.linear(x, weight.t()))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Quaternion-valued layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide a number of quaternion-valued layers to implement quaternion neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from htorch.layers import QLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model with two quaternion-valued dense layers, and a split ReLU (ReLU applied on each component separately)\n",
    "model = nn.Sequential(\n",
    "    QLinear(4, 20, bias=True),\n",
    "    nn.ReLU(),\n",
    "    QLinear(20, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real part: tensor([[0.6880, 0.0847, 0.9757, 0.5077],\n",
       "        [0.9420, 0.6194, 0.4373, 0.2948]])\n",
       "imaginary part (i): tensor([[0.0664, 0.8679, 0.6496, 0.0596],\n",
       "        [0.6619, 0.8849, 0.8469, 0.7168]])\n",
       "imaginary part (j): tensor([[0.1720, 0.2184, 0.5141, 0.4599],\n",
       "        [0.5464, 0.5286, 0.7514, 0.4183]])\n",
       "imaginary part (k): tensor([[0.4162, 0.6309, 0.1841, 0.1809],\n",
       "        [0.7883, 0.7348, 0.5910, 0.0243]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = quaternion.QuaternionTensor(torch.rand(2, 16))\n",
    "x.shape\n",
    "#model1(x)\n",
    "y=model(x)\n",
    "y.shape\n",
    "#print(model(x))\n",
    "x\n",
    "torch.rand(2,16)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = QLinear(1,20,bias=True)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide layers to easily integrate quaternion-valued and real-valued blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htorch.layers import QuaternionToReal\n",
    "from torch.nn import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    QLinear(4, 10),\n",
    "    QuaternionToReal(10), # Take the absolute value of each output\n",
    "    Softmax(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [notebooks/training.ipynb] for an example of a full training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
