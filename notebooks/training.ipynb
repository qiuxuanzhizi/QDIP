{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quaternion PyTorch - Training a QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from htorch import quaternion, layers, utils\n",
    "from htorch.layers import QConv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net=QConv2d(1, 20, kernel_size=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net.bias[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a `collate_fn` to convert any standard image dataset to a quaternion format (by using the RGB values as imaginary components and the greyscale version as real component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Standard loading for the CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "data = CIFAR10(root='data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the data using a custom collate_fn function to convert to quaternion-valued images\n",
    "loader = torch.utils.data.DataLoader(data, batch_size=8, shuffle=True, \n",
    "    collate_fn=utils.convert_data_for_quaternion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = next(iter(loader))\n",
    "print(xb.shape) # We now have 4 input channels as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7961, -0.8039, -0.8118,  ..., -0.6863, -0.7882, -0.8353],\n",
       "          [-0.7804, -0.7961, -0.8118,  ..., -0.5608, -0.8118, -0.8745],\n",
       "          [-0.7804, -0.7882, -0.7961,  ..., -0.4745, -0.5294, -0.8196],\n",
       "          ...,\n",
       "          [ 0.3176,  0.3255,  0.3020,  ..., -0.8275, -0.8118, -0.7961],\n",
       "          [ 0.2706,  0.2314,  0.2314,  ..., -0.8902, -0.8667, -0.8353],\n",
       "          [ 0.0980,  0.2000,  0.1529,  ..., -0.8667, -0.8745, -0.8824]],\n",
       "\n",
       "         [[-0.7255, -0.7412, -0.7412,  ..., -0.7020, -0.7647, -0.8196],\n",
       "          [-0.7176, -0.7333, -0.7412,  ..., -0.6157, -0.8039, -0.8431],\n",
       "          [-0.7255, -0.7255, -0.7255,  ..., -0.5216, -0.5686, -0.8196],\n",
       "          ...,\n",
       "          [-0.1843, -0.1922, -0.1765,  ..., -0.8824, -0.8667, -0.8588],\n",
       "          [-0.2471, -0.2784, -0.2549,  ..., -0.9137, -0.8980, -0.8824],\n",
       "          [-0.3333, -0.2941, -0.3255,  ..., -0.9059, -0.9059, -0.9059]],\n",
       "\n",
       "         [[-0.5608, -0.5765, -0.5843,  ..., -0.7490, -0.8118, -0.8667],\n",
       "          [-0.5451, -0.5765, -0.5922,  ..., -0.6706, -0.8431, -0.8902],\n",
       "          [-0.5608, -0.5686, -0.5765,  ..., -0.5765, -0.6078, -0.8510],\n",
       "          ...,\n",
       "          [-0.6235, -0.6235, -0.6157,  ..., -0.9294, -0.9216, -0.9216],\n",
       "          [-0.7020, -0.6941, -0.6627,  ..., -0.9529, -0.9373, -0.9373],\n",
       "          [-0.7098, -0.7020, -0.7176,  ..., -0.9529, -0.9529, -0.9529]],\n",
       "\n",
       "         [[-0.7277, -0.7411, -0.7443,  ..., -0.7026, -0.7770, -0.8296],\n",
       "          [-0.7167, -0.7341, -0.7452,  ..., -0.6055, -0.8107, -0.8578],\n",
       "          [-0.7231, -0.7263, -0.7295,  ..., -0.5137, -0.5613, -0.8231],\n",
       "          ...,\n",
       "          [-0.0843, -0.0866, -0.0835,  ..., -0.8712, -0.8564, -0.8471],\n",
       "          [-0.1442, -0.1734, -0.1560,  ..., -0.9111, -0.8930, -0.8745],\n",
       "          [-0.2473, -0.1929, -0.2272,  ..., -0.8994, -0.9018, -0.9041]]],\n",
       "\n",
       "\n",
       "        [[[-0.4353, -0.4902, -0.4980,  ..., -0.5922, -0.5922, -0.6000],\n",
       "          [-0.6157, -0.6314, -0.6392,  ..., -0.5843, -0.5843, -0.5843],\n",
       "          [-0.6235, -0.6235, -0.6157,  ..., -0.5686, -0.5686, -0.5765],\n",
       "          ...,\n",
       "          [-0.6784, -0.6941, -0.6863,  ..., -0.5765, -0.5686, -0.5843],\n",
       "          [-0.7255, -0.7020, -0.6941,  ..., -0.5922, -0.6235, -0.6471],\n",
       "          [-0.7412, -0.7255, -0.7098,  ..., -0.6392, -0.6706, -0.6706]],\n",
       "\n",
       "         [[-0.3020, -0.3490, -0.3569,  ..., -0.4431, -0.4353, -0.4510],\n",
       "          [-0.4588, -0.4745, -0.4745,  ..., -0.4353, -0.4353, -0.4431],\n",
       "          [-0.4667, -0.4588, -0.4510,  ..., -0.4353, -0.4275, -0.4431],\n",
       "          ...,\n",
       "          [-0.4118, -0.3882, -0.3804,  ..., -0.3647, -0.3412, -0.3490],\n",
       "          [-0.4431, -0.3961, -0.4039,  ..., -0.4039, -0.4353, -0.4510],\n",
       "          [-0.4353, -0.4039, -0.4039,  ..., -0.4275, -0.4510, -0.4588]],\n",
       "\n",
       "         [[-0.0353, -0.0667, -0.0745,  ..., -0.1137, -0.1059, -0.1216],\n",
       "          [-0.1529, -0.1529, -0.1529,  ..., -0.1059, -0.1059, -0.1137],\n",
       "          [-0.1451, -0.1294, -0.1294,  ..., -0.0980, -0.0902, -0.1059],\n",
       "          ...,\n",
       "          [-0.4745, -0.4745, -0.4667,  ..., -0.4353, -0.4039, -0.3882],\n",
       "          [-0.5216, -0.4902, -0.4902,  ..., -0.4588, -0.4980, -0.5137],\n",
       "          [-0.5137, -0.4824, -0.4824,  ..., -0.4824, -0.5137, -0.5294]],\n",
       "\n",
       "         [[-0.3114, -0.3590, -0.3668,  ..., -0.4501, -0.4446, -0.4579],\n",
       "          [-0.4708, -0.4847, -0.4870,  ..., -0.4422, -0.4422, -0.4477],\n",
       "          [-0.4768, -0.4705, -0.4635,  ..., -0.4367, -0.4312, -0.4445],\n",
       "          ...,\n",
       "          [-0.4986, -0.4895, -0.4816,  ..., -0.4360, -0.4163, -0.4238],\n",
       "          [-0.5364, -0.4982, -0.5005,  ..., -0.4664, -0.4987, -0.5167],\n",
       "          [-0.5356, -0.5089, -0.5043,  ..., -0.4970, -0.5237, -0.5301]]],\n",
       "\n",
       "\n",
       "        [[[-0.4039, -0.4118, -0.4118,  ..., -0.4196, -0.4196, -0.4196],\n",
       "          [-0.4039, -0.4118, -0.4118,  ..., -0.4196, -0.4196, -0.4196],\n",
       "          [-0.4039, -0.4118, -0.4118,  ..., -0.4118, -0.4118, -0.4118],\n",
       "          ...,\n",
       "          [-0.3490, -0.3569, -0.3569,  ..., -0.3725, -0.3725, -0.3725],\n",
       "          [-0.3490, -0.3569, -0.3569,  ..., -0.3725, -0.3725, -0.3725],\n",
       "          [-0.3490, -0.3569, -0.3569,  ..., -0.3647, -0.3647, -0.3647]],\n",
       "\n",
       "         [[ 0.0039, -0.0118, -0.0039,  ..., -0.0118, -0.0118, -0.0118],\n",
       "          [-0.0039, -0.0118, -0.0118,  ..., -0.0196, -0.0196, -0.0196],\n",
       "          [-0.0039, -0.0118, -0.0118,  ..., -0.0118, -0.0118, -0.0118],\n",
       "          ...,\n",
       "          [ 0.0588,  0.0431,  0.0431,  ...,  0.0431,  0.0431,  0.0431],\n",
       "          [ 0.0510,  0.0431,  0.0431,  ...,  0.0431,  0.0431,  0.0431],\n",
       "          [ 0.0510,  0.0431,  0.0431,  ...,  0.0510,  0.0510,  0.0510]],\n",
       "\n",
       "         [[ 0.4275,  0.4118,  0.4118,  ...,  0.4039,  0.4039,  0.4039],\n",
       "          [ 0.4196,  0.3961,  0.4039,  ...,  0.3961,  0.3961,  0.3961],\n",
       "          [ 0.4196,  0.4039,  0.4039,  ...,  0.4039,  0.4039,  0.4039],\n",
       "          ...,\n",
       "          [ 0.4745,  0.4588,  0.4588,  ...,  0.4510,  0.4510,  0.4510],\n",
       "          [ 0.4745,  0.4588,  0.4588,  ...,  0.4510,  0.4510,  0.4510],\n",
       "          [ 0.4745,  0.4588,  0.4588,  ...,  0.4588,  0.4588,  0.4588]],\n",
       "\n",
       "         [[-0.0697, -0.0830, -0.0784,  ..., -0.0863, -0.0863, -0.0863],\n",
       "          [-0.0752, -0.0848, -0.0839,  ..., -0.0918, -0.0918, -0.0918],\n",
       "          [-0.0752, -0.0839, -0.0839,  ..., -0.0839, -0.0839, -0.0839],\n",
       "          ...,\n",
       "          [-0.0157, -0.0290, -0.0290,  ..., -0.0346, -0.0346, -0.0346],\n",
       "          [-0.0203, -0.0290, -0.0290,  ..., -0.0346, -0.0346, -0.0346],\n",
       "          [-0.0203, -0.0290, -0.0290,  ..., -0.0268, -0.0268, -0.0268]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.1843, -0.1608, -0.1529,  ..., -0.1922, -0.2078, -0.2157],\n",
       "          [-0.1608, -0.1451, -0.1373,  ..., -0.1922, -0.2235, -0.2392],\n",
       "          [-0.1059, -0.1059, -0.1059,  ..., -0.1765, -0.1843, -0.2157],\n",
       "          ...,\n",
       "          [ 0.7804,  0.7961,  0.8431,  ...,  0.8667,  0.8431,  0.8353],\n",
       "          [ 0.6000,  0.6392,  0.7020,  ...,  0.8039,  0.7882,  0.7725],\n",
       "          [ 0.3333,  0.3569,  0.4353,  ...,  0.5451,  0.5294,  0.5059]],\n",
       "\n",
       "         [[-0.2157, -0.1922, -0.1843,  ..., -0.2314, -0.2471, -0.2549],\n",
       "          [-0.1922, -0.1765, -0.1686,  ..., -0.2314, -0.2627, -0.2784],\n",
       "          [-0.1373, -0.1373, -0.1373,  ..., -0.2157, -0.2235, -0.2549],\n",
       "          ...,\n",
       "          [ 0.7569,  0.7725,  0.8196,  ...,  0.8039,  0.7804,  0.7725],\n",
       "          [ 0.5765,  0.6157,  0.6784,  ...,  0.7412,  0.7255,  0.7098],\n",
       "          [ 0.3098,  0.3412,  0.4118,  ...,  0.4902,  0.4667,  0.4510]],\n",
       "\n",
       "         [[-0.2078, -0.1843, -0.1765,  ..., -0.1922, -0.2000, -0.2078],\n",
       "          [-0.1843, -0.1686, -0.1608,  ..., -0.1843, -0.2157, -0.2314],\n",
       "          [-0.1294, -0.1294, -0.1294,  ..., -0.1686, -0.1765, -0.2078],\n",
       "          ...,\n",
       "          [ 0.7176,  0.7333,  0.7804,  ...,  0.7804,  0.7569,  0.7490],\n",
       "          [ 0.5373,  0.5765,  0.6392,  ...,  0.7176,  0.7020,  0.6863],\n",
       "          [ 0.2784,  0.3020,  0.3804,  ...,  0.4667,  0.4510,  0.4275]],\n",
       "\n",
       "         [[-0.2054, -0.1819, -0.1740,  ..., -0.2152, -0.2299, -0.2378],\n",
       "          [-0.1819, -0.1662, -0.1583,  ..., -0.2143, -0.2456, -0.2613],\n",
       "          [-0.1270, -0.1270, -0.1270,  ..., -0.1986, -0.2064, -0.2378],\n",
       "          ...,\n",
       "          [ 0.7593,  0.7750,  0.8221,  ...,  0.8199,  0.7964,  0.7885],\n",
       "          [ 0.5790,  0.6182,  0.6809,  ...,  0.7572,  0.7415,  0.7258],\n",
       "          [ 0.3132,  0.3414,  0.4152,  ...,  0.5039,  0.4836,  0.4647]]],\n",
       "\n",
       "\n",
       "        [[[-0.6471, -0.6627, -0.6549,  ..., -0.0824, -0.1686,  0.0118],\n",
       "          [-0.4510, -0.6627, -0.6627,  ..., -0.2314, -0.3020, -0.0588],\n",
       "          [-0.6314, -0.7333, -0.6314,  ...,  0.0118,  0.0039,  0.1059],\n",
       "          ...,\n",
       "          [-0.0275,  0.0039,  0.0667,  ..., -0.0824, -0.1216, -0.0980],\n",
       "          [ 0.0588,  0.2706,  0.2314,  ...,  0.0667,  0.0667,  0.1059],\n",
       "          [ 0.5294,  0.3725,  0.2549,  ...,  0.1765,  0.1843,  0.1922]],\n",
       "\n",
       "         [[-0.6627, -0.6549, -0.6078,  ..., -0.0902, -0.1608, -0.0118],\n",
       "          [-0.4745, -0.6627, -0.6235,  ..., -0.2549, -0.2941, -0.0745],\n",
       "          [-0.6549, -0.7255, -0.5843,  ..., -0.0118,  0.0118,  0.0824],\n",
       "          ...,\n",
       "          [-0.0980, -0.0824,  0.0039,  ..., -0.0902, -0.1294, -0.1216],\n",
       "          [ 0.0039,  0.1843,  0.1608,  ...,  0.0588,  0.0510,  0.0667],\n",
       "          [ 0.5059,  0.3255,  0.2157,  ...,  0.1686,  0.1765,  0.1686]],\n",
       "\n",
       "         [[-0.6078, -0.6627, -0.7804,  ..., -0.2706, -0.2784, -0.2078],\n",
       "          [-0.4353, -0.6784, -0.7882,  ..., -0.3725, -0.3961, -0.2627],\n",
       "          [-0.6941, -0.8118, -0.8118,  ..., -0.2157, -0.2235, -0.1294],\n",
       "          ...,\n",
       "          [-0.3255, -0.2863, -0.1843,  ..., -0.3176, -0.3569, -0.3647],\n",
       "          [-0.2157, -0.0118, -0.0275,  ..., -0.1216, -0.1137, -0.1216],\n",
       "          [ 0.3412,  0.1373,  0.0039,  ..., -0.0039,  0.0118, -0.0039]],\n",
       "\n",
       "         [[-0.6517, -0.6581, -0.6415,  ..., -0.1084, -0.1765, -0.0271],\n",
       "          [-0.4630, -0.6645, -0.6540,  ..., -0.2613, -0.3081, -0.0913],\n",
       "          [-0.6523, -0.7376, -0.6243,  ..., -0.0280, -0.0174,  0.0652],\n",
       "          ...,\n",
       "          [-0.1029, -0.0798,  0.0012,  ..., -0.1138, -0.1530, -0.1422],\n",
       "          [-0.0047,  0.1877,  0.1604,  ...,  0.0406,  0.0369,  0.0569],\n",
       "          [ 0.4941,  0.3181,  0.2032,  ...,  0.1513,  0.1600,  0.1560]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8275,  0.8980,  0.9451,  ...,  0.8039,  0.6471,  0.4039],\n",
       "          [ 0.8667,  0.9686,  0.9922,  ...,  0.5529,  0.3333, -0.2157],\n",
       "          [ 0.4824,  0.7333,  0.7098,  ..., -0.1294, -0.2078, -0.3490],\n",
       "          ...,\n",
       "          [-0.0118,  0.0353,  0.0824,  ..., -0.0510, -0.0431, -0.1294],\n",
       "          [-0.0353, -0.0275,  0.0118,  ...,  0.0745,  0.1294,  0.1137],\n",
       "          [-0.0902, -0.0745, -0.0667,  ...,  0.2627,  0.3412,  0.3725]],\n",
       "\n",
       "         [[ 0.8667,  0.9294,  0.9686,  ...,  0.8510,  0.7333,  0.4902],\n",
       "          [ 0.8980,  0.9922,  1.0000,  ...,  0.6000,  0.4039, -0.1451],\n",
       "          [ 0.5059,  0.7333,  0.7020,  ..., -0.0824, -0.1529, -0.3020],\n",
       "          ...,\n",
       "          [ 0.0510,  0.0824,  0.1137,  ..., -0.0275, -0.0118, -0.1137],\n",
       "          [ 0.0353,  0.0353,  0.0824,  ...,  0.1059,  0.1608,  0.1451],\n",
       "          [-0.0196,  0.0039,  0.0196,  ...,  0.2941,  0.3725,  0.4039]],\n",
       "\n",
       "         [[ 1.0000,  0.9765,  0.9843,  ...,  0.9608,  0.9373,  0.7961],\n",
       "          [ 0.9922,  1.0000,  1.0000,  ...,  0.7098,  0.5686,  0.0510],\n",
       "          [ 0.5765,  0.7647,  0.7333,  ...,  0.0118, -0.0510, -0.1843],\n",
       "          ...,\n",
       "          [-0.2078, -0.1843, -0.1608,  ..., -0.1765, -0.2157, -0.2000],\n",
       "          [-0.2157, -0.2314, -0.2235,  ..., -0.0275,  0.0118,  0.0353],\n",
       "          [-0.2627, -0.2706, -0.2941,  ...,  0.1686,  0.2471,  0.2863]],\n",
       "\n",
       "         [[ 0.8701,  0.9253,  0.9633,  ...,  0.8493,  0.7307,  0.4992],\n",
       "          [ 0.8993,  0.9859,  0.9976,  ...,  0.5984,  0.4016, -0.1438],\n",
       "          [ 0.5068,  0.7368,  0.7078,  ..., -0.0857, -0.1577, -0.3026],\n",
       "          ...,\n",
       "          [ 0.0027,  0.0379,  0.0730,  ..., -0.0515, -0.0444, -0.1282],\n",
       "          [-0.0144, -0.0139,  0.0264,  ...,  0.0813,  0.1344,  0.1232],\n",
       "          [-0.0684, -0.0508, -0.0419,  ...,  0.2704,  0.3488,  0.3811]]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "Variable(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "real part: tensor([[[[-0.7961, -0.8039, -0.8118,  ..., -0.6863, -0.7882, -0.8353],\n",
       "          [-0.7804, -0.7961, -0.8118,  ..., -0.5608, -0.8118, -0.8745],\n",
       "          [-0.7804, -0.7882, -0.7961,  ..., -0.4745, -0.5294, -0.8196],\n",
       "          ...,\n",
       "          [ 0.3176,  0.3255,  0.3020,  ..., -0.8275, -0.8118, -0.7961],\n",
       "          [ 0.2706,  0.2314,  0.2314,  ..., -0.8902, -0.8667, -0.8353],\n",
       "          [ 0.0980,  0.2000,  0.1529,  ..., -0.8667, -0.8745, -0.8824]]],\n",
       "\n",
       "\n",
       "        [[[-0.4353, -0.4902, -0.4980,  ..., -0.5922, -0.5922, -0.6000],\n",
       "          [-0.6157, -0.6314, -0.6392,  ..., -0.5843, -0.5843, -0.5843],\n",
       "          [-0.6235, -0.6235, -0.6157,  ..., -0.5686, -0.5686, -0.5765],\n",
       "          ...,\n",
       "          [-0.6784, -0.6941, -0.6863,  ..., -0.5765, -0.5686, -0.5843],\n",
       "          [-0.7255, -0.7020, -0.6941,  ..., -0.5922, -0.6235, -0.6471],\n",
       "          [-0.7412, -0.7255, -0.7098,  ..., -0.6392, -0.6706, -0.6706]]],\n",
       "\n",
       "\n",
       "        [[[-0.4039, -0.4118, -0.4118,  ..., -0.4196, -0.4196, -0.4196],\n",
       "          [-0.4039, -0.4118, -0.4118,  ..., -0.4196, -0.4196, -0.4196],\n",
       "          [-0.4039, -0.4118, -0.4118,  ..., -0.4118, -0.4118, -0.4118],\n",
       "          ...,\n",
       "          [-0.3490, -0.3569, -0.3569,  ..., -0.3725, -0.3725, -0.3725],\n",
       "          [-0.3490, -0.3569, -0.3569,  ..., -0.3725, -0.3725, -0.3725],\n",
       "          [-0.3490, -0.3569, -0.3569,  ..., -0.3647, -0.3647, -0.3647]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.1843, -0.1608, -0.1529,  ..., -0.1922, -0.2078, -0.2157],\n",
       "          [-0.1608, -0.1451, -0.1373,  ..., -0.1922, -0.2235, -0.2392],\n",
       "          [-0.1059, -0.1059, -0.1059,  ..., -0.1765, -0.1843, -0.2157],\n",
       "          ...,\n",
       "          [ 0.7804,  0.7961,  0.8431,  ...,  0.8667,  0.8431,  0.8353],\n",
       "          [ 0.6000,  0.6392,  0.7020,  ...,  0.8039,  0.7882,  0.7725],\n",
       "          [ 0.3333,  0.3569,  0.4353,  ...,  0.5451,  0.5294,  0.5059]]],\n",
       "\n",
       "\n",
       "        [[[-0.6471, -0.6627, -0.6549,  ..., -0.0824, -0.1686,  0.0118],\n",
       "          [-0.4510, -0.6627, -0.6627,  ..., -0.2314, -0.3020, -0.0588],\n",
       "          [-0.6314, -0.7333, -0.6314,  ...,  0.0118,  0.0039,  0.1059],\n",
       "          ...,\n",
       "          [-0.0275,  0.0039,  0.0667,  ..., -0.0824, -0.1216, -0.0980],\n",
       "          [ 0.0588,  0.2706,  0.2314,  ...,  0.0667,  0.0667,  0.1059],\n",
       "          [ 0.5294,  0.3725,  0.2549,  ...,  0.1765,  0.1843,  0.1922]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8275,  0.8980,  0.9451,  ...,  0.8039,  0.6471,  0.4039],\n",
       "          [ 0.8667,  0.9686,  0.9922,  ...,  0.5529,  0.3333, -0.2157],\n",
       "          [ 0.4824,  0.7333,  0.7098,  ..., -0.1294, -0.2078, -0.3490],\n",
       "          ...,\n",
       "          [-0.0118,  0.0353,  0.0824,  ..., -0.0510, -0.0431, -0.1294],\n",
       "          [-0.0353, -0.0275,  0.0118,  ...,  0.0745,  0.1294,  0.1137],\n",
       "          [-0.0902, -0.0745, -0.0667,  ...,  0.2627,  0.3412,  0.3725]]]])\n",
       "imaginary part (i): tensor([[[[-0.7255, -0.7412, -0.7412,  ..., -0.7020, -0.7647, -0.8196],\n",
       "          [-0.7176, -0.7333, -0.7412,  ..., -0.6157, -0.8039, -0.8431],\n",
       "          [-0.7255, -0.7255, -0.7255,  ..., -0.5216, -0.5686, -0.8196],\n",
       "          ...,\n",
       "          [-0.1843, -0.1922, -0.1765,  ..., -0.8824, -0.8667, -0.8588],\n",
       "          [-0.2471, -0.2784, -0.2549,  ..., -0.9137, -0.8980, -0.8824],\n",
       "          [-0.3333, -0.2941, -0.3255,  ..., -0.9059, -0.9059, -0.9059]]],\n",
       "\n",
       "\n",
       "        [[[-0.3020, -0.3490, -0.3569,  ..., -0.4431, -0.4353, -0.4510],\n",
       "          [-0.4588, -0.4745, -0.4745,  ..., -0.4353, -0.4353, -0.4431],\n",
       "          [-0.4667, -0.4588, -0.4510,  ..., -0.4353, -0.4275, -0.4431],\n",
       "          ...,\n",
       "          [-0.4118, -0.3882, -0.3804,  ..., -0.3647, -0.3412, -0.3490],\n",
       "          [-0.4431, -0.3961, -0.4039,  ..., -0.4039, -0.4353, -0.4510],\n",
       "          [-0.4353, -0.4039, -0.4039,  ..., -0.4275, -0.4510, -0.4588]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0039, -0.0118, -0.0039,  ..., -0.0118, -0.0118, -0.0118],\n",
       "          [-0.0039, -0.0118, -0.0118,  ..., -0.0196, -0.0196, -0.0196],\n",
       "          [-0.0039, -0.0118, -0.0118,  ..., -0.0118, -0.0118, -0.0118],\n",
       "          ...,\n",
       "          [ 0.0588,  0.0431,  0.0431,  ...,  0.0431,  0.0431,  0.0431],\n",
       "          [ 0.0510,  0.0431,  0.0431,  ...,  0.0431,  0.0431,  0.0431],\n",
       "          [ 0.0510,  0.0431,  0.0431,  ...,  0.0510,  0.0510,  0.0510]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.2157, -0.1922, -0.1843,  ..., -0.2314, -0.2471, -0.2549],\n",
       "          [-0.1922, -0.1765, -0.1686,  ..., -0.2314, -0.2627, -0.2784],\n",
       "          [-0.1373, -0.1373, -0.1373,  ..., -0.2157, -0.2235, -0.2549],\n",
       "          ...,\n",
       "          [ 0.7569,  0.7725,  0.8196,  ...,  0.8039,  0.7804,  0.7725],\n",
       "          [ 0.5765,  0.6157,  0.6784,  ...,  0.7412,  0.7255,  0.7098],\n",
       "          [ 0.3098,  0.3412,  0.4118,  ...,  0.4902,  0.4667,  0.4510]]],\n",
       "\n",
       "\n",
       "        [[[-0.6627, -0.6549, -0.6078,  ..., -0.0902, -0.1608, -0.0118],\n",
       "          [-0.4745, -0.6627, -0.6235,  ..., -0.2549, -0.2941, -0.0745],\n",
       "          [-0.6549, -0.7255, -0.5843,  ..., -0.0118,  0.0118,  0.0824],\n",
       "          ...,\n",
       "          [-0.0980, -0.0824,  0.0039,  ..., -0.0902, -0.1294, -0.1216],\n",
       "          [ 0.0039,  0.1843,  0.1608,  ...,  0.0588,  0.0510,  0.0667],\n",
       "          [ 0.5059,  0.3255,  0.2157,  ...,  0.1686,  0.1765,  0.1686]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8667,  0.9294,  0.9686,  ...,  0.8510,  0.7333,  0.4902],\n",
       "          [ 0.8980,  0.9922,  1.0000,  ...,  0.6000,  0.4039, -0.1451],\n",
       "          [ 0.5059,  0.7333,  0.7020,  ..., -0.0824, -0.1529, -0.3020],\n",
       "          ...,\n",
       "          [ 0.0510,  0.0824,  0.1137,  ..., -0.0275, -0.0118, -0.1137],\n",
       "          [ 0.0353,  0.0353,  0.0824,  ...,  0.1059,  0.1608,  0.1451],\n",
       "          [-0.0196,  0.0039,  0.0196,  ...,  0.2941,  0.3725,  0.4039]]]])\n",
       "imaginary part (j): tensor([[[[-0.5608, -0.5765, -0.5843,  ..., -0.7490, -0.8118, -0.8667],\n",
       "          [-0.5451, -0.5765, -0.5922,  ..., -0.6706, -0.8431, -0.8902],\n",
       "          [-0.5608, -0.5686, -0.5765,  ..., -0.5765, -0.6078, -0.8510],\n",
       "          ...,\n",
       "          [-0.6235, -0.6235, -0.6157,  ..., -0.9294, -0.9216, -0.9216],\n",
       "          [-0.7020, -0.6941, -0.6627,  ..., -0.9529, -0.9373, -0.9373],\n",
       "          [-0.7098, -0.7020, -0.7176,  ..., -0.9529, -0.9529, -0.9529]]],\n",
       "\n",
       "\n",
       "        [[[-0.0353, -0.0667, -0.0745,  ..., -0.1137, -0.1059, -0.1216],\n",
       "          [-0.1529, -0.1529, -0.1529,  ..., -0.1059, -0.1059, -0.1137],\n",
       "          [-0.1451, -0.1294, -0.1294,  ..., -0.0980, -0.0902, -0.1059],\n",
       "          ...,\n",
       "          [-0.4745, -0.4745, -0.4667,  ..., -0.4353, -0.4039, -0.3882],\n",
       "          [-0.5216, -0.4902, -0.4902,  ..., -0.4588, -0.4980, -0.5137],\n",
       "          [-0.5137, -0.4824, -0.4824,  ..., -0.4824, -0.5137, -0.5294]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4275,  0.4118,  0.4118,  ...,  0.4039,  0.4039,  0.4039],\n",
       "          [ 0.4196,  0.3961,  0.4039,  ...,  0.3961,  0.3961,  0.3961],\n",
       "          [ 0.4196,  0.4039,  0.4039,  ...,  0.4039,  0.4039,  0.4039],\n",
       "          ...,\n",
       "          [ 0.4745,  0.4588,  0.4588,  ...,  0.4510,  0.4510,  0.4510],\n",
       "          [ 0.4745,  0.4588,  0.4588,  ...,  0.4510,  0.4510,  0.4510],\n",
       "          [ 0.4745,  0.4588,  0.4588,  ...,  0.4588,  0.4588,  0.4588]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.2078, -0.1843, -0.1765,  ..., -0.1922, -0.2000, -0.2078],\n",
       "          [-0.1843, -0.1686, -0.1608,  ..., -0.1843, -0.2157, -0.2314],\n",
       "          [-0.1294, -0.1294, -0.1294,  ..., -0.1686, -0.1765, -0.2078],\n",
       "          ...,\n",
       "          [ 0.7176,  0.7333,  0.7804,  ...,  0.7804,  0.7569,  0.7490],\n",
       "          [ 0.5373,  0.5765,  0.6392,  ...,  0.7176,  0.7020,  0.6863],\n",
       "          [ 0.2784,  0.3020,  0.3804,  ...,  0.4667,  0.4510,  0.4275]]],\n",
       "\n",
       "\n",
       "        [[[-0.6078, -0.6627, -0.7804,  ..., -0.2706, -0.2784, -0.2078],\n",
       "          [-0.4353, -0.6784, -0.7882,  ..., -0.3725, -0.3961, -0.2627],\n",
       "          [-0.6941, -0.8118, -0.8118,  ..., -0.2157, -0.2235, -0.1294],\n",
       "          ...,\n",
       "          [-0.3255, -0.2863, -0.1843,  ..., -0.3176, -0.3569, -0.3647],\n",
       "          [-0.2157, -0.0118, -0.0275,  ..., -0.1216, -0.1137, -0.1216],\n",
       "          [ 0.3412,  0.1373,  0.0039,  ..., -0.0039,  0.0118, -0.0039]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0000,  0.9765,  0.9843,  ...,  0.9608,  0.9373,  0.7961],\n",
       "          [ 0.9922,  1.0000,  1.0000,  ...,  0.7098,  0.5686,  0.0510],\n",
       "          [ 0.5765,  0.7647,  0.7333,  ...,  0.0118, -0.0510, -0.1843],\n",
       "          ...,\n",
       "          [-0.2078, -0.1843, -0.1608,  ..., -0.1765, -0.2157, -0.2000],\n",
       "          [-0.2157, -0.2314, -0.2235,  ..., -0.0275,  0.0118,  0.0353],\n",
       "          [-0.2627, -0.2706, -0.2941,  ...,  0.1686,  0.2471,  0.2863]]]])\n",
       "imaginary part (k): tensor([[[[-0.7277, -0.7411, -0.7443,  ..., -0.7026, -0.7770, -0.8296],\n",
       "          [-0.7167, -0.7341, -0.7452,  ..., -0.6055, -0.8107, -0.8578],\n",
       "          [-0.7231, -0.7263, -0.7295,  ..., -0.5137, -0.5613, -0.8231],\n",
       "          ...,\n",
       "          [-0.0843, -0.0866, -0.0835,  ..., -0.8712, -0.8564, -0.8471],\n",
       "          [-0.1442, -0.1734, -0.1560,  ..., -0.9111, -0.8930, -0.8745],\n",
       "          [-0.2473, -0.1929, -0.2272,  ..., -0.8994, -0.9018, -0.9041]]],\n",
       "\n",
       "\n",
       "        [[[-0.3114, -0.3590, -0.3668,  ..., -0.4501, -0.4446, -0.4579],\n",
       "          [-0.4708, -0.4847, -0.4870,  ..., -0.4422, -0.4422, -0.4477],\n",
       "          [-0.4768, -0.4705, -0.4635,  ..., -0.4367, -0.4312, -0.4445],\n",
       "          ...,\n",
       "          [-0.4986, -0.4895, -0.4816,  ..., -0.4360, -0.4163, -0.4238],\n",
       "          [-0.5364, -0.4982, -0.5005,  ..., -0.4664, -0.4987, -0.5167],\n",
       "          [-0.5356, -0.5089, -0.5043,  ..., -0.4970, -0.5237, -0.5301]]],\n",
       "\n",
       "\n",
       "        [[[-0.0697, -0.0830, -0.0784,  ..., -0.0863, -0.0863, -0.0863],\n",
       "          [-0.0752, -0.0848, -0.0839,  ..., -0.0918, -0.0918, -0.0918],\n",
       "          [-0.0752, -0.0839, -0.0839,  ..., -0.0839, -0.0839, -0.0839],\n",
       "          ...,\n",
       "          [-0.0157, -0.0290, -0.0290,  ..., -0.0346, -0.0346, -0.0346],\n",
       "          [-0.0203, -0.0290, -0.0290,  ..., -0.0346, -0.0346, -0.0346],\n",
       "          [-0.0203, -0.0290, -0.0290,  ..., -0.0268, -0.0268, -0.0268]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.2054, -0.1819, -0.1740,  ..., -0.2152, -0.2299, -0.2378],\n",
       "          [-0.1819, -0.1662, -0.1583,  ..., -0.2143, -0.2456, -0.2613],\n",
       "          [-0.1270, -0.1270, -0.1270,  ..., -0.1986, -0.2064, -0.2378],\n",
       "          ...,\n",
       "          [ 0.7593,  0.7750,  0.8221,  ...,  0.8199,  0.7964,  0.7885],\n",
       "          [ 0.5790,  0.6182,  0.6809,  ...,  0.7572,  0.7415,  0.7258],\n",
       "          [ 0.3132,  0.3414,  0.4152,  ...,  0.5039,  0.4836,  0.4647]]],\n",
       "\n",
       "\n",
       "        [[[-0.6517, -0.6581, -0.6415,  ..., -0.1084, -0.1765, -0.0271],\n",
       "          [-0.4630, -0.6645, -0.6540,  ..., -0.2613, -0.3081, -0.0913],\n",
       "          [-0.6523, -0.7376, -0.6243,  ..., -0.0280, -0.0174,  0.0652],\n",
       "          ...,\n",
       "          [-0.1029, -0.0798,  0.0012,  ..., -0.1138, -0.1530, -0.1422],\n",
       "          [-0.0047,  0.1877,  0.1604,  ...,  0.0406,  0.0369,  0.0569],\n",
       "          [ 0.4941,  0.3181,  0.2032,  ...,  0.1513,  0.1600,  0.1560]]],\n",
       "\n",
       "\n",
       "        [[[ 0.8701,  0.9253,  0.9633,  ...,  0.8493,  0.7307,  0.4992],\n",
       "          [ 0.8993,  0.9859,  0.9976,  ...,  0.5984,  0.4016, -0.1438],\n",
       "          [ 0.5068,  0.7368,  0.7078,  ..., -0.0857, -0.1577, -0.3026],\n",
       "          ...,\n",
       "          [ 0.0027,  0.0379,  0.0730,  ..., -0.0515, -0.0444, -0.1282],\n",
       "          [-0.0144, -0.0139,  0.0264,  ...,  0.0813,  0.1344,  0.1232],\n",
       "          [-0.0684, -0.0508, -0.0419,  ...,  0.2704,  0.3488,  0.3811]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable1=Variable(quaternion.QuaternionTensor(xb))\n",
    "quaternion.QuaternionTensor(variable1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Building the QNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a simple QNN with three convolutional blocks with split-ReLU activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    layers.QConv2d(1, 20, kernel_size=10, bias=True), # We only have 1 channel in terms of quaternions\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2), # Max-pool is okay because it acts on the channels\n",
    "    layers.QConv2d(20, 20, kernel_size=10, bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Flatten(),\n",
    "    layers.QLinear(20, 10),\n",
    "    layers.QuaternionToReal(10), # Take the absolute value before the softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model is working correctly\n",
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, everything is classical PyTorch:\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.798\n",
      "[1,  4000] loss: 1.562\n",
      "[1,  6000] loss: 1.467\n",
      "[2,  2000] loss: 1.352\n",
      "[2,  4000] loss: 1.321\n",
      "[2,  6000] loss: 1.295\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting an existing nn.Module\n",
    "\n",
    "Using the new [torch.fx](https://pytorch.org/docs/stable/fx.html) functionals, we can also convert an existing PyTorch's `nn.Module` into a quaternion-valued one, provided all shapes are divisible by 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model is similar to the previous one, but all dimensions are multiplied by 4\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(4, 80, kernel_size=10, bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Conv2d(80, 80, kernel_size=10, bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(80, 40),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 40])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to a QNN and run on the previous set of images\n",
    "utils.convert_to_quaternion(model)(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7327, 0.2658, 0.0568, 0.7222],\n",
       "         [0.1554, 0.1372, 0.5214, 0.0433],\n",
       "         [0.8462, 0.7988, 0.9529, 0.5796]],\n",
       "\n",
       "        [[0.4696, 0.8617, 0.3132, 0.2324],\n",
       "         [0.4662, 0.8223, 0.7987, 0.0827],\n",
       "         [0.9092, 0.2384, 0.1312, 0.1774]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=a.flatten(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=a.flatten(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7327, 0.2658, 0.0568, 0.7222, 0.1554, 0.1372, 0.5214, 0.0433, 0.8462,\n",
       "        0.7988, 0.9529, 0.5796, 0.4696, 0.8617, 0.3132, 0.2324, 0.4662, 0.8223,\n",
       "        0.7987, 0.0827, 0.9092, 0.2384, 0.1312, 0.1774])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7327, 0.2658, 0.0568, 0.7222],\n",
       "         [0.1554, 0.1372, 0.5214, 0.0433],\n",
       "         [0.8462, 0.7988, 0.9529, 0.5796]],\n",
       "\n",
       "        [[0.4696, 0.8617, 0.3132, 0.2324],\n",
       "         [0.4662, 0.8223, 0.7987, 0.0827],\n",
       "         [0.9092, 0.2384, 0.1312, 0.1774]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7327, 0.2658, 0.0568, 0.7222, 0.1554, 0.1372, 0.5214, 0.0433, 0.8462,\n",
       "         0.7988, 0.9529, 0.5796],\n",
       "        [0.4696, 0.8617, 0.3132, 0.2324, 0.4662, 0.8223, 0.7987, 0.0827, 0.9092,\n",
       "         0.2384, 0.1312, 0.1774]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
